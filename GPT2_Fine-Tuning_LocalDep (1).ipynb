{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a8acad-a7ae-45f8-99fe-032129d9927c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: transformers in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (4.57.6)\n",
      "Requirement already satisfied: peft in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: accelerate in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: evaluate in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: nltk in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: onnx in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (1.20.1)\n",
      "Requirement already satisfied: onnxruntime in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (1.24.1)\n",
      "Requirement already satisfied: gradio in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (6.5.1)\n",
      "Requirement already satisfied: optimum[onnxruntime] in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (0.36.2)\n",
      "Requirement already satisfied: packaging in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: psutil in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from peft) (2.10.0)\n",
      "Requirement already satisfied: click in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from onnx) (5.29.3)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from onnx) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from onnxruntime) (25.12.19)\n",
      "Requirement already satisfied: sympy in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.2.2)\n",
      "Requirement already satisfied: brotli>=1.1.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.129.0)\n",
      "Requirement already satisfied: ffmpy in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.3 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (2.0.3)\n",
      "Requirement already satisfied: groovy~=0.1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: jinja2<4.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (3.11.7)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (12.0.0)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (2.12.4)\n",
      "Requirement already satisfied: pydub in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.0.22)\n",
      "Requirement already satisfied: pytz>=2017.2 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (2025.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.52.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.17.4)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from gradio) (0.40.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.4.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.2.0)\n",
      "Requirement already satisfied: optimum-onnx[onnxruntime] in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from optimum[onnxruntime]) (0.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: colorama in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: networkx>=2.5.1 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: setuptools in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from torch>=1.13.0->peft) (82.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\\AppData\\Local\\anaconda3\\Lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ransformers (C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ransformers (C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ransformers (C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers peft accelerate evaluate nltk onnx onnxruntime gradio optimum[onnxruntime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31584476-0dc6-484f-be40-f081ea53a47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550b8973-969a-4415-b6af-2b9d266ea257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Cell 2 — Imports\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from transformers import (\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    EarlyStoppingCallback,\n",
    "    pipeline,\n",
    ")\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58da096-d148-4126-a932-0bc222a59586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lyrics', 'genre']\n",
      "{'lyrics': \"[Intro: Method Man w/ sample] + (Sunny valentine). We got butter (8X). (The gun'll go the gun'll go.... The gun'll go...). [Raekwon]. Aiyo one thing for sure keep you of all. Keep a nice crib fly away keep to the point. Keep niggaz outta ya face who snakes. Keep bitches in they place keep the mac in a special place. Keep moving for papes keep cool keep doing what you doing. Keep it fly keep me in the crates. Cuz I will erase shit on the real note you'se a waste. It's right here for you I will lace you. Rip you and brace you put a nice W up on ya face. Word to mother you could get chased. It's nothing to taste blood on a thug if he gotta go. All I know is we be giving grace. This is a place from where we make tapes. We make 'em everywhere still in all we be making base. Y'all be making paste these little niggaz they be making shapes. Our shit is art yours is traced. [Chorus: Sunny Valentine]. This is the way that we rolling in the streets. You know when we roll we be packing that heat. The gun'll go the gun'll go the gun'll go the gun'll go. The gun'll go the gun'll go the gun'll go the gun'll go. The gun'll go the gun'll go.... [Method Man]. This is Poverty Island man these animals don't run. Slums where the ambulance don't come. Who got the best base? Fiends waiting to smoke some. Approach something ask him where he getting that coke from. My dudes hug blocks like samurai shogun. Cuz no V and no ones equalling no fun. Who want a treat they know huh? Body to go numb. My woman need funds plus her hair and her toes done. It is what it is though you fuck with the kid flow. That make it hard to get dough the harder to get gold. Harder the piff blow harder when it snow. The pinky and the wrist glow this here what we live for. Get gwop then get low but first thought. We gotta get the work off the gift and the curse boss. Yeah see I'm the shit yo the dirt in the fit no. Hustling from the get-go the motto is get more. [Chorus]. [Masta Killa]. We was quiet flashy brothers strapped all along. With the dirty .38 long twelve hour shift gate. Took case state to state you think he won't hold his weight?. Put ya money on the plate and watch it get scrapped. We get ape up in that club off that juice and Henn. And it's a no win situation fucking with them. You mean like Ewing at the front at the rim finger roll a Dutch. Million dollar stages touched techs gauges bust. Trust no one the lone shogun rugged Timb boot stomper. Damaging lyrical mass destruction launcher. Nothing can calm the quakeage when I break kid. Peace to my brothers up north doing state bids. [Chorus]. [Chorus 2: Sunny Valentine]. Whoa... this is the way we be rolling in the club. You know when we roll we be packing .32 snubs. The gun'll go the gun'll go the gun'll go the gun'll go. The gun'll go the gun'll go the gun'll go the gun'll go. The gun'll go the gun'll go the gun'll go the gun'll go. [Outro: sample to fade]. We got butter...\", 'genre': 'Hip Hop'}\n"
     ]
    }
   ],
   "source": [
    "## Cell 3 — Load dataset\n",
    "dataset = load_dataset(\"halaction/song-lyrics\", split=\"train[:1000]\")\n",
    "print(dataset.column_names)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb371e8-8b72-4f17-8097-8ef5356db894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using text column: lyrics\n",
      "Rows: 1000\n"
     ]
    }
   ],
   "source": [
    "## Cell 4 — Choose text column + clean rows\n",
    "candidate_columns = [\"lyrics\", \"text\", \"song\", \"content\"]\n",
    "text_col = next((c for c in candidate_columns if c in dataset.column_names), dataset.column_names[0])\n",
    "\n",
    "dataset = dataset.filter(lambda x: x[text_col] is not None and x[text_col].strip() != \"\")\n",
    "dataset = dataset.select_columns([text_col])\n",
    "print(\"Using text column:\", text_col)\n",
    "print(\"Rows:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2d9fa5-59b8-4c6c-975a-552189889e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell 5 — Tokenizer setup\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 pad token fix\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb40c406-c150-4f4b-8d56-828a977f8b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "## Cell 6 — Tokenization function + map\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    texts = [t + tokenizer.eos_token for t in batch[text_col]]\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()  # Causal LM labels\n",
    "    return tokenized\n",
    "\n",
    "tokenized_data = dataset.map(tokenize_function, batched=True, remove_columns=[text_col])\n",
    "tokenized_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "splits = tokenized_data.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = splits[\"train\"]\n",
    "eval_dataset = splits[\"test\"]\n",
    "\n",
    "print(train_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f44ee07-1314-48e7-baf6-7a3e5ded87b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:2285: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Cell 7 — Load GPT-2 and apply LoRA\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfbbcb8f-c359-404b-bca4-2274bca1ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell 8 — Training arguments (includes weight decay)\n",
    "\n",
    "common_args = dict(\n",
    "    output_dir=\"./gpt2-lyrics-lora\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,  # required regularization\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_steps=20,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# transformers version compatibility:\n",
    "# - older versions use evaluation_strategy\n",
    "# - newer versions use eval_strategy\n",
    "try:\n",
    "    training_args = TrainingArguments(evaluation_strategy=\"epoch\", **common_args)\n",
    "except TypeError:\n",
    "    training_args = TrainingArguments(eval_strategy=\"epoch\", **common_args)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbced9e-d8d7-4b49-bc8a-6844a9ad9774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shweiss\\AppData\\Local\\Temp\\ipykernel_20024\\2783257490.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "## Cell 9 — Trainer with early stopping\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc80b7a-a513-47fb-8117-ceb5f318d792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 3:06:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.683700</td>\n",
       "      <td>3.362211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.596300</td>\n",
       "      <td>3.334249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.545200</td>\n",
       "      <td>3.319573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.542200</td>\n",
       "      <td>3.313650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.529300</td>\n",
       "      <td>3.312150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3121497631073, 'eval_runtime': 45.5956, 'eval_samples_per_second': 2.193, 'eval_steps_per_second': 0.548, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "## Cell 10 — Train + evaluate\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1666929e-a75d-40f9-9d15-26db933a5326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2-lyrics-merged\\\\tokenizer_config.json',\n",
       " './gpt2-lyrics-merged\\\\special_tokens_map.json',\n",
       " './gpt2-lyrics-merged\\\\vocab.json',\n",
       " './gpt2-lyrics-merged\\\\merges.txt',\n",
       " './gpt2-lyrics-merged\\\\added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cell 11 — Save LoRA adapter + merged model\n",
    "\n",
    "trainer.model.save_pretrained(\"./gpt2-lyrics-lora-adapter\")\n",
    "tokenizer.save_pretrained(\"./gpt2-lyrics-lora-adapter\")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"./gpt2-lyrics-merged\")\n",
    "tokenizer.save_pretrained(\"./gpt2-lyrics-merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8381a4a-d65a-4eec-8c0d-0ea1d715880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\optimum\\exporters\\base.py:151: FutureWarning: functools.partial will be a method descriptor in future Python versions; wrap it in staticmethod() if you want to preserve the old behavior\n",
      "  self._normalized_config = self.NORMALIZED_CONFIG_CLASS(self._config)\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\cache_utils.py:132: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not self.is_initialized or self.keys.numel() == 0:\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\masking_utils.py:207: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (padding_length := kv_length + kv_offset - attention_mask.shape[-1]) > 0:\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\masking_utils.py:235: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if padding_mask is not None and padding_mask.shape[-1] > kv_length:\n",
      "C:\\Users\\shweiss\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torch\\onnx\\_internal\\torchscript_exporter\\symbolic_opset11.py:954: UserWarning: Exporting aten::index operator of advanced indexing in opset 18 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  return opset9.index(g, self, index)\n",
      "Found different candidate ONNX initializers (likely duplicate) for the tied weights:\n",
      "\tlm_head.weight: {'onnx::MatMul_3300'}\n",
      "\ttransformer.wte.weight: {'transformer.wte.weight'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX export complete: C:\\Users\\shweiss\\gpt2-lyrics-onnx\n"
     ]
    }
   ],
   "source": [
    "## Cell 12 — Export to ONNX\n",
    "\n",
    "from optimum.onnxruntime import ORTModelForCausalLM\n",
    "\n",
    "onnx_dir = Path(\"./gpt2-lyrics-onnx\")\n",
    "onnx_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ort_model = ORTModelForCausalLM.from_pretrained(\"./gpt2-lyrics-merged\", export=True)\n",
    "ort_model.save_pretrained(onnx_dir)\n",
    "tokenizer.save_pretrained(onnx_dir)\n",
    "\n",
    "print(\"ONNX export complete:\", onnx_dir.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a84288d5-4c58-4ff9-8607-f8ce10d72851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "## Cell 13 — Generate text helper\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "generator = pipeline(\"text-generation\", model=\"./gpt2-lyrics-merged\", tokenizer=tokenizer, device=device)\n",
    "\n",
    "def generate_lyrics(prompt, max_new_tokens=80, temperature=0.9, top_p=0.95):\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=1.1,\n",
    "        num_return_sequences=1,\n",
    "    )[0][\"generated_text\"]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51955eb-c161-46cc-8958-4dcfc90af1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cell 14 — Gradio app\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate_lyrics,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, label=\"Prompt\"),\n",
    "        gr.Slider(20, 200, value=80, step=1, label=\"max_new_tokens\"),\n",
    "        gr.Slider(0.1, 1.5, value=0.9, step=0.05, label=\"temperature\"),\n",
    "        gr.Slider(0.5, 1.0, value=0.95, step=0.01, label=\"top_p\"),\n",
    "    ],\n",
    "    outputs=gr.Textbox(lines=8, label=\"Generated Lyrics\"),\n",
    "    title=\"GPT-2 Lyrics Generator (LoRA Fine-Tuned)\",\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22c53034-a9d6-4acd-9371-3beab2f54ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Lyrics:\n",
      " I walk alone beneath the city lights. Like a star gazing sky overhead to keep me awake at night when I need something else on my side... The air feels like heaven, as if there's nothing left of it but tears and hope for more.. And every single inch in this world\n",
      "BLEU Score: 0.09548024812323944\n",
      "\n",
      "Qualitative checklist:\n",
      "- Coherence: Does the text stay on a consistent theme?\n",
      "- Relevance: Does it continue the prompt naturally?\n",
      "- Creativity: Are wording and imagery varied?\n",
      "- Fluency: Does it read smoothly?\n"
     ]
    }
   ],
   "source": [
    "## Cell 15 — BLEU evaluation + qualitative review notes\n",
    "\n",
    "prompt = \"I walk alone beneath the city lights\"\n",
    "generated_text = generate_lyrics(prompt, max_new_tokens=50)\n",
    "print(\"Generated Lyrics:\\n\", generated_text)\n",
    "\n",
    "# Replace this with a real reference continuation from a held-out lyric sample\n",
    "reference_text = \"I walk alone beneath the city lights, chasing echoes of a fading night\"\n",
    "reference = [reference_text.split()]\n",
    "candidate = generated_text.split()\n",
    "\n",
    "bleu_score = sentence_bleu(reference, candidate, smoothing_function=SmoothingFunction().method1)\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "\n",
    "print(\"\\nQualitative checklist:\")\n",
    "print(\"- Coherence: Does the text stay on a consistent theme?\")\n",
    "print(\"- Relevance: Does it continue the prompt naturally?\")\n",
    "print(\"- Creativity: Are wording and imagery varied?\")\n",
    "print(\"- Fluency: Does it read smoothly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f07c3-0a18-4902-90de-4267eadd174e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
